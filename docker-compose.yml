version: "3.9"

x-airflow-common: &airflow-common
  build: .
  environment:
    - AIRFLOW__CORE__EXECUTOR=${AIRFLOW__CORE__EXECUTOR}
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
    - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
    - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW__WEBSERVER__SECRET_KEY}
  volumes:
    - ./dags:/opt/airflow/dags
    - ./data:/opt/airflow/data
    - ./logs:/opt/airflow/logs    

  depends_on:
    psql_dev:
      condition: service_healthy

services:
  psql_dev:
    image: postgres:14
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5  

  airflow:
    <<: *airflow-common
    image: apache/airflow:2.9.3    
    restart: always
    command: >
      bash -c "
        pip install duckdb pandas pyarrow requests gtfs-realtime-bindings &&
        airflow db init &&
        airflow users create --username admin --password admin \
            --firstname Admin --lastname User --role Admin --email admin@example.com || true &&
        airflow webserver & airflow scheduler
      "
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5

  neo4j_db:
    image: neo4j:ubi9
    environment:
      - NEO4J_AUTH=none
    volumes: 
      - $HOME/neo4j/data:/data
    ports:
      - "7474:7474"
      - "7687:7687"
    tty: true  

volumes:
  postgres_data: